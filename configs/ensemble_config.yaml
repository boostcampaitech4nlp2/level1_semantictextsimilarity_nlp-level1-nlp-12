
wandb:
  project: sts
  name: kjh
  info: ensemble_test # ⭐

path:
  # train_path: ./data/aug_data/train_auged.csv
  train_path: ./data/raw_data/train.csv
  dev_path: ./data/raw_data/dev.csv
  test_path: ./data/raw_data/dev.csv
  predict_path: ./data/raw_data/test.csv

data:
  shuffle: True

model:
  name: klue/roberta-small # beomi/KcELECTRA-base | beomi/KcELECTRA-base | klue/bert-base | xlm-roberta-base | jhgan/ko-sroberta-sts
  saved_name: roberta-large # ⭐ 저장할 모델 이름
  saved_checkpoint: checkpoints/model # model checkpoint 저장할 폴더 명
  saved_contrastive_checkpoint : checkpoints/contrastive
  model_ckpt_path:  Freezing1-3_neg_pair--epoch=12--val_pearson=0.918.ckpt # ⭐ model inference 시 사용할 ckpt 경로를 입력해주세요
  model_ckpt_path2 : roberta-small--epoch=00--val_pearson=0.434

loss_func: L1Loss # L1Loss | ...

train:
  seed: 42
  gpus: 1
  batch_size: 8
  max_epoch: 1
  learning_rate: 1e-5

optimizer: AdamW

scheduler: StepLR



